{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher.app')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent instantiation \n",
    "agent = Agent(state_size = state_size, action_size = action_size, num_agents = num_agents, random_seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=2000, max_t=100,  maxlen=100, print_every=100):\n",
    "    scores = []\n",
    "    scores_deque = deque(maxlen=maxlen)\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        score = np.zeros(num_agents)\n",
    "        agent.reset()\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            score += env_info.rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        scores_deque.append(np.mean(score))\n",
    "        scores.append(np.mean(score))\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), np.mean(score)), end=\"\")\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "        if np.mean(scores_deque) >= 30.0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print(f'Environment solved in {i_episode-100} episodes, Average Score: {scores_deque}')\n",
    "            break\n",
    "            \n",
    "    return scores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 26.42\tScore: 35.44\n",
      "Episode 111\tAverage Score: 30.33\tScore: 35.86Environment solved in 11 episodes, Average Score: deque([1.2069999730214476, 1.6069999640807509, 1.8194999593310057, 2.0389999544247983, 2.4604999450035394, 3.074999931268394, 3.021999932453036, 4.046499909553677, 2.971499933581799, 4.097499908413738, 5.75549987135455, 7.095499841403216, 7.7159998275339605, 9.39899978991598, 11.415999744832515, 12.936499710846693, 16.033499641623347, 18.118499595019966, 17.800999602116644, 23.049499484803526, 25.004999441094697, 27.679999381303787, 28.687499358784407, 29.33949934421107, 31.118999304436148, 32.52699927296489, 34.58749922690913, 36.34549918761477, 36.04849919425324, 37.429999163374305, 37.892499153036624, 38.12049914794043, 38.10649914825335, 37.71699915695935, 37.71149915708229, 37.567999160289766, 37.048999171890316, 37.783999155461785, 36.561999182775615, 36.82349917693064, 36.00499919522554, 36.615999181568625, 37.1024991706945, 37.83499915432185, 37.704999157227576, 37.593999159708616, 37.06149917161092, 37.13999916985631, 37.273999166861174, 36.50799918398261, 36.692499179858714, 35.14799921438098, 35.73749920120463, 35.96299919616431, 35.38299920912832, 35.784499200154094, 34.30599923320115, 36.89449917534366, 37.49349916195497, 36.76349917827174, 37.315999165922406, 36.224999190308154, 36.88549917554483, 36.68649917999282, 36.70299917962402, 35.17549921376631, 33.43449925268069, 36.006499195192006, 36.69699917975813, 36.540999183245006, 35.42349920822308, 34.65699922535568, 36.311499188374725, 35.97199919596314, 36.53299918342382, 37.28649916658178, 35.57599920481444, 37.04799917191267, 36.193999191001055, 36.466499184910205, 37.0484991719015, 37.25399916730821, 36.790499177668245, 36.0124991950579, 37.07049917140976, 35.77599920034409, 36.561999182775615, 36.56899918261915, 35.44399920776486, 36.234999190084636, 35.34699920993298, 36.73549917889759, 36.26049918951467, 36.7729991780594, 36.18799919113517, 36.457499185111374, 36.59149918211624, 36.8414991765283, 37.06649917149916, 35.857999198511244], maxlen=100)\n"
     ]
    }
   ],
   "source": [
    "# function calling\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deque_list = [1.2069999730214476, 1.6069999640807509, 1.8194999593310057, 2.0389999544247983, 2.4604999450035394, 3.074999931268394, 3.021999932453036, 4.046499909553677, 2.971499933581799, 4.097499908413738, 5.75549987135455, 7.095499841403216, 7.7159998275339605, 9.39899978991598, 11.415999744832515, 12.936499710846693, 16.033499641623347, 18.118499595019966, 17.800999602116644, 23.049499484803526, 25.004999441094697, 27.679999381303787, 28.687499358784407, 29.33949934421107, 31.118999304436148, 32.52699927296489, 34.58749922690913, 36.34549918761477, 36.04849919425324, 37.429999163374305, 37.892499153036624, 38.12049914794043, 38.10649914825335, 37.71699915695935, 37.71149915708229, 37.567999160289766, 37.048999171890316, 37.783999155461785, 36.561999182775615, 36.82349917693064, 36.00499919522554, 36.615999181568625, 37.1024991706945, 37.83499915432185, 37.704999157227576, 37.593999159708616, 37.06149917161092, 37.13999916985631, 37.273999166861174, 36.50799918398261, 36.692499179858714, 35.14799921438098, 35.73749920120463, 35.96299919616431, 35.38299920912832, 35.784499200154094, 34.30599923320115, 36.89449917534366, 37.49349916195497, 36.76349917827174, 37.315999165922406, 36.224999190308154, 36.88549917554483, 36.68649917999282, 36.70299917962402, 35.17549921376631, 33.43449925268069, 36.006499195192006, 36.69699917975813, 36.540999183245006, 35.42349920822308, 34.65699922535568, 36.311499188374725, 35.97199919596314, 36.53299918342382, 37.28649916658178, 35.57599920481444, 37.04799917191267, 36.193999191001055, 36.466499184910205, 37.0484991719015, 37.25399916730821, 36.790499177668245, 36.0124991950579, 37.07049917140976, 35.77599920034409, 36.561999182775615, 36.56899918261915, 35.44399920776486, 36.234999190084636, 35.34699920993298, 36.73549917889759, 36.26049918951467, 36.7729991780594, 36.18799919113517, 36.457499185111374, 36.59149918211624, 36.8414991765283, 37.06649917149916, 35.857999198511244]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment solved in 11 episodes, Avaerage score 30.327969322117053\n"
     ]
    }
   ],
   "source": [
    "print(f'Environment solved in 11 episodes, Average score {np.mean(deque_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fcs1.weight',\n",
       "              tensor([[-3.4484e-02,  4.0698e-02,  1.8745e-02,  ..., -3.4630e-02,\n",
       "                        1.5230e-02, -1.9624e-02],\n",
       "                      [-1.6438e-02, -1.0840e-02, -3.1831e-02,  ..., -1.6233e-02,\n",
       "                        4.7095e-02,  2.6114e-02],\n",
       "                      [ 1.5521e-02, -3.7615e-02,  2.9927e-02,  ...,  2.8646e-02,\n",
       "                       -3.6226e-02,  4.1519e-02],\n",
       "                      ...,\n",
       "                      [ 2.7129e-02,  8.5879e-03, -1.5778e-03,  ...,  2.4524e-03,\n",
       "                        6.5304e-03, -3.5688e-02],\n",
       "                      [-4.0225e-02,  2.7878e-03, -4.3699e-02,  ...,  2.9153e-02,\n",
       "                        5.8747e-03,  2.0124e-02],\n",
       "                      [-4.7653e-02,  1.4195e-02,  3.0660e-02,  ..., -9.3771e-03,\n",
       "                       -1.0931e-02,  8.0280e-03]])),\n",
       "             ('fcs1.bias',\n",
       "              tensor([-0.0804, -0.0718,  0.1695,  0.0276, -0.1480, -0.1546, -0.1497,\n",
       "                      -0.1263, -0.1051, -0.0927,  0.1294, -0.0714,  0.1601, -0.0398,\n",
       "                      -0.1406, -0.0638, -0.0772, -0.1197, -0.1624,  0.0061, -0.1351,\n",
       "                      -0.0501, -0.0458, -0.1005, -0.0066, -0.1349, -0.0566,  0.1541,\n",
       "                       0.1610,  0.0140,  0.0405,  0.1546,  0.1672, -0.0821,  0.0275,\n",
       "                      -0.0344, -0.1194,  0.1545,  0.1381,  0.0075,  0.1435,  0.0465,\n",
       "                       0.1149,  0.0737,  0.0824,  0.0621,  0.0874,  0.1530,  0.0681,\n",
       "                      -0.1110,  0.0640,  0.1738,  0.1443,  0.1098, -0.0660,  0.1720,\n",
       "                       0.0318, -0.0936, -0.0065,  0.1265, -0.1599, -0.0399,  0.1298,\n",
       "                      -0.0480, -0.0703, -0.0469,  0.0570, -0.1343,  0.0220,  0.0447,\n",
       "                       0.0460, -0.0035,  0.0857, -0.0103,  0.1350,  0.1152, -0.1203,\n",
       "                      -0.0340,  0.1354, -0.0175, -0.0532, -0.0109, -0.0400, -0.0607,\n",
       "                       0.0385,  0.1467,  0.0252,  0.0979,  0.1344, -0.1133, -0.1238,\n",
       "                      -0.0257,  0.0519, -0.0211, -0.0816, -0.1198,  0.0051,  0.1295,\n",
       "                       0.0075,  0.1658, -0.0824,  0.1607, -0.1116,  0.1383,  0.0190,\n",
       "                       0.1731,  0.1657, -0.0596, -0.0127, -0.0473,  0.0387, -0.0858,\n",
       "                      -0.0405, -0.1055,  0.1060,  0.1375,  0.0192, -0.0053, -0.1306,\n",
       "                      -0.1586, -0.1343, -0.1289, -0.1432,  0.0816, -0.1328,  0.0834,\n",
       "                       0.1158, -0.0007,  0.0412,  0.1086, -0.1579,  0.1504,  0.1714,\n",
       "                       0.1661, -0.0680,  0.1069, -0.0640,  0.0271,  0.1456,  0.0365,\n",
       "                       0.0637, -0.0463, -0.0826,  0.1420, -0.1571,  0.0304, -0.0168,\n",
       "                      -0.0490, -0.1701, -0.1035, -0.0994,  0.0262,  0.0679, -0.1582,\n",
       "                      -0.0669, -0.1660,  0.1190, -0.1599, -0.0233, -0.0248, -0.0954,\n",
       "                       0.1251,  0.0745,  0.0908,  0.1227, -0.0869,  0.0842,  0.1407,\n",
       "                      -0.0400, -0.0142,  0.0165, -0.1709, -0.0185, -0.0208, -0.1266,\n",
       "                       0.1273, -0.1532, -0.0697,  0.1025,  0.0270,  0.0706,  0.0075,\n",
       "                      -0.1620, -0.1250, -0.0589, -0.1172, -0.1084, -0.0563,  0.1552,\n",
       "                       0.1349,  0.0350, -0.1117, -0.1049,  0.1705,  0.0216,  0.0197,\n",
       "                      -0.0987, -0.0889,  0.0856, -0.0149, -0.0182, -0.0858, -0.1290,\n",
       "                      -0.1123, -0.1714,  0.1594,  0.0256,  0.0244,  0.1307,  0.0875,\n",
       "                      -0.0254,  0.1078,  0.0028, -0.1697,  0.1411, -0.1026, -0.1315,\n",
       "                      -0.0402,  0.0425,  0.1369, -0.1723, -0.1629, -0.1160, -0.1017,\n",
       "                       0.1712, -0.0027,  0.1263,  0.0491,  0.1017, -0.0903,  0.0758,\n",
       "                       0.0632,  0.0599, -0.1307, -0.0600,  0.1479, -0.0381, -0.1265,\n",
       "                      -0.1474, -0.0353,  0.0806, -0.0514,  0.1242,  0.0742, -0.1393,\n",
       "                       0.0018,  0.1587,  0.1083, -0.0625, -0.1292,  0.0452,  0.0836,\n",
       "                      -0.0358, -0.1485,  0.1682,  0.0841, -0.1733,  0.0077, -0.0391,\n",
       "                       0.1615,  0.0919,  0.0461, -0.0513, -0.1283,  0.0544,  0.0704,\n",
       "                       0.0037,  0.1530,  0.0999, -0.1455, -0.0096, -0.0776, -0.0080,\n",
       "                       0.0159,  0.0214,  0.1067,  0.1200,  0.0092, -0.0654, -0.0867,\n",
       "                       0.0902,  0.0630,  0.1475, -0.1468, -0.1329, -0.1042,  0.0768,\n",
       "                       0.1354, -0.0140, -0.1457,  0.0277, -0.1497,  0.1112, -0.1307,\n",
       "                       0.0253,  0.0019,  0.0876, -0.1206,  0.0781,  0.0048,  0.0213,\n",
       "                      -0.1181,  0.1645, -0.0314, -0.1014, -0.0488, -0.0517,  0.1731,\n",
       "                       0.1275,  0.0008,  0.1677, -0.0010,  0.0205,  0.0315, -0.0159,\n",
       "                      -0.1317,  0.0518, -0.0135,  0.0688,  0.0963,  0.1261,  0.0465,\n",
       "                       0.0087, -0.0750,  0.1630, -0.1541, -0.0910,  0.0218,  0.0836,\n",
       "                       0.1010, -0.1539,  0.0605, -0.1448,  0.1233, -0.1479,  0.0309,\n",
       "                       0.0287, -0.0371,  0.0789,  0.1200,  0.0606,  0.0365,  0.1705,\n",
       "                       0.1644, -0.1199,  0.1567,  0.1522,  0.0006,  0.0581, -0.0703,\n",
       "                      -0.0678,  0.0287, -0.0775,  0.0453,  0.0736,  0.1019, -0.1241,\n",
       "                      -0.0882, -0.0304,  0.0697, -0.0702, -0.0823, -0.0411,  0.0594,\n",
       "                       0.0071, -0.0437,  0.0442, -0.1306, -0.1670,  0.0984,  0.1557,\n",
       "                      -0.0062,  0.0909,  0.1226,  0.1493,  0.0135, -0.0163, -0.1670,\n",
       "                      -0.0118, -0.0493, -0.0052,  0.1665, -0.0566, -0.1412,  0.1584,\n",
       "                       0.0082, -0.1129,  0.0076, -0.0028,  0.0576,  0.1609, -0.0954,\n",
       "                      -0.1014, -0.0113,  0.0965,  0.1734, -0.1117, -0.0830, -0.0116,\n",
       "                      -0.1436])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 4.3903e-02, -4.1915e-02, -2.5049e-02,  ..., -1.9080e-02,\n",
       "                       -4.4551e-02,  2.6746e-02],\n",
       "                      [ 2.0958e-03, -4.3686e-02,  2.9502e-02,  ...,  3.4327e-02,\n",
       "                       -1.9854e-02, -5.2365e-02],\n",
       "                      [ 1.7065e-02, -4.6171e-02,  1.0033e-02,  ...,  4.9270e-02,\n",
       "                        3.2234e-02,  1.6935e-02],\n",
       "                      ...,\n",
       "                      [-1.9123e-02, -2.3325e-02,  3.6429e-02,  ...,  3.7512e-02,\n",
       "                       -5.7628e-02, -3.2879e-02],\n",
       "                      [-7.7917e-03, -1.7878e-02,  4.4827e-02,  ...,  2.0828e-02,\n",
       "                        3.5159e-02,  5.6362e-02],\n",
       "                      [-4.1067e-02, -5.5367e-02,  5.6222e-02,  ...,  4.3703e-02,\n",
       "                       -8.3455e-03,  1.0809e-02]])),\n",
       "             ('fc2.bias',\n",
       "              tensor(1.00000e-02 *\n",
       "                     [-1.4915,  4.2431, -4.8264, -2.1400,  1.1780,  2.2707,  2.7464,\n",
       "                      -2.8737,  3.2659, -3.5901,  4.5734,  4.8285, -1.5786,  2.6990,\n",
       "                      -3.9559, -1.1618,  1.1048, -4.5642, -2.7401, -0.1785,  4.3782,\n",
       "                      -2.9789, -0.2220, -4.4690, -2.8910, -2.0026, -2.0971,  0.2432,\n",
       "                       3.5822,  0.9196,  1.3836, -2.1271, -4.3731, -2.4868,  0.6373,\n",
       "                      -3.4749,  3.2960, -2.8771, -2.3889, -0.8972, -4.5710, -3.6291,\n",
       "                       2.0434,  0.5718, -3.0888, -2.4501, -4.7138,  2.3671,  4.3568,\n",
       "                      -3.6823,  1.7592, -1.3399,  3.5559,  1.9368, -0.1646,  4.8136,\n",
       "                       2.6199, -3.2232, -3.6871,  4.4071,  2.0096,  4.4048, -1.3879,\n",
       "                       2.4288,  0.4957,  4.8662,  1.4669, -4.7753, -1.7713,  1.2310,\n",
       "                      -2.1965, -2.4281, -3.7842,  4.5050, -3.9590, -2.4739,  0.3338,\n",
       "                      -3.7796,  0.2806,  1.9407,  4.6846,  3.5895,  0.6768,  4.9617,\n",
       "                      -2.4623, -4.7119, -4.7798,  3.5827,  3.6474, -3.1083, -1.4979,\n",
       "                       0.0067,  0.6203, -2.0929,  0.3407, -3.4912,  4.1627, -0.6653,\n",
       "                      -4.1970, -0.1395, -0.2156, -1.0768, -0.8094,  1.3896,  3.6794,\n",
       "                      -0.2703,  4.2989, -3.2084, -0.0149,  1.2752,  4.8421,  3.8741,\n",
       "                      -4.2593, -0.7018,  2.0669, -1.0948, -3.4435,  2.7019,  3.4106,\n",
       "                       2.2864, -1.9620,  0.8690,  3.7970,  3.3789, -1.6109,  2.9228,\n",
       "                      -2.6588, -0.2844,  4.0835, -3.0318, -2.4537,  2.0284,  0.6993,\n",
       "                      -2.1044, -3.4131, -1.0319, -4.7051, -3.0334, -2.2358,  2.6075,\n",
       "                      -0.7750,  3.8362, -4.3191,  2.5851,  2.0966, -0.3763, -0.9374,\n",
       "                       0.0206, -4.0782,  1.1210, -4.7177,  2.1457,  1.5065, -2.3038,\n",
       "                      -1.9144, -4.3637, -2.9684,  2.2604, -3.0488,  0.7249, -4.1867,\n",
       "                      -3.9097,  1.1672, -3.2361, -2.7531,  1.0240, -2.0459,  1.6062,\n",
       "                      -3.3925, -1.2839,  2.2901,  1.4627,  3.7229, -4.9045, -3.8709,\n",
       "                      -0.5739, -3.4451,  3.4618,  3.2044, -0.4772, -4.4999, -1.7978,\n",
       "                      -1.6388, -2.3151, -4.9317,  3.0538,  2.7909, -2.8399,  0.6826,\n",
       "                       0.9770,  2.9218,  0.0891,  3.8818,  1.0802,  1.2654,  2.7471,\n",
       "                      -0.5134,  0.7960, -4.8012,  1.4680, -0.3495,  0.8576,  1.2178,\n",
       "                       0.2237, -2.0828, -0.6286,  3.8010,  2.9608,  0.8423, -1.4464,\n",
       "                      -4.8907,  2.6877,  3.8508,  0.8246, -4.3384, -4.4059, -1.1906,\n",
       "                      -2.1030, -2.0145,  3.5877, -2.4759, -4.1967, -0.7597, -4.0207,\n",
       "                       2.7439,  2.2566,  2.2812, -1.0733, -2.2543,  4.3023,  3.1185,\n",
       "                       4.6899,  4.1656,  2.3751,  3.9421, -1.0684, -4.6480,  2.3333,\n",
       "                      -1.6348, -2.7661, -4.3532, -0.6746,  3.5423,  3.2760, -4.2189,\n",
       "                      -3.4721, -2.7218,  0.9650,  1.9113,  3.5105, -4.5593, -0.7605,\n",
       "                       1.8661,  3.5638, -2.4168,  2.9808, -2.3933,  4.7335, -4.2565,\n",
       "                       0.5055, -2.8521,  3.2696, -0.9975,  3.7376,  1.2046, -2.0457,\n",
       "                       3.1190,  1.2258, -4.5370, -3.0701, -2.3532, -1.5315, -4.2653,\n",
       "                      -2.5080, -4.4453,  3.8510, -3.8867,  0.0407,  1.9603, -3.5709,\n",
       "                      -1.5718, -1.8142, -4.2674,  1.7299,  4.6735, -3.8588, -2.9543,\n",
       "                      -2.1162,  2.7129,  3.3914,  1.6390, -0.4844, -3.4867,  1.7744,\n",
       "                      -4.1354,  2.9405,  1.2474, -4.5973,  2.2940,  4.8829])),\n",
       "             ('fc3.weight',\n",
       "              tensor(1.00000e-03 *\n",
       "                     [[-2.1602, -0.1568,  0.1543,  1.4392, -2.4587, -1.9855,  0.8630,\n",
       "                       -2.8679, -1.2769, -2.2969, -1.1625,  0.6397, -2.4717,  2.2322,\n",
       "                        2.2422,  2.9160, -0.3406,  2.2228, -2.9321, -0.9148, -1.2267,\n",
       "                        2.3387, -0.5801,  0.2378, -1.1604, -1.0112, -2.9429, -2.6257,\n",
       "                        0.6799, -0.1964, -2.7913,  1.7306,  0.6910,  1.9277, -1.9295,\n",
       "                        0.1539,  2.6598,  0.7855, -0.6609,  0.0479, -2.7455,  0.8274,\n",
       "                       -2.4946,  2.9572, -1.8807, -0.9175, -1.1961,  0.9522, -2.9802,\n",
       "                       -1.9764,  2.8506,  1.2664,  2.7771, -0.1780, -0.0030,  2.8314,\n",
       "                       -1.6562,  2.9051, -2.6921,  2.9766,  0.9214, -2.8137, -1.8241,\n",
       "                       -0.8893,  2.8363,  0.7285, -2.4464,  1.9790,  2.2330, -1.9409,\n",
       "                       -0.1345, -2.3335,  1.1722,  1.8763,  0.3628, -0.6283, -1.7726,\n",
       "                       -0.9923, -1.1900,  2.5571,  2.2081,  1.1965, -0.3472,  2.0146,\n",
       "                       -2.6388,  1.9525, -0.5716,  1.9960,  2.1500,  0.1850, -1.4909,\n",
       "                        0.9833, -0.4583,  2.0357,  2.0746,  0.4491,  1.8287,  2.1136,\n",
       "                       -0.0716, -2.0145, -2.6306, -1.7370,  1.9049, -0.7742,  1.7206,\n",
       "                       -2.6873, -2.7896,  1.9265, -0.6442,  1.2943, -2.9991, -1.6298,\n",
       "                        0.4222, -1.0735, -2.3371, -0.9660, -1.6805,  1.9949, -0.0783,\n",
       "                        2.9211,  1.7620, -0.8566,  0.3738, -2.9344,  2.2557,  2.3992,\n",
       "                       -2.4328, -0.4135,  1.0723, -1.6723, -0.4888, -1.3437, -1.6314,\n",
       "                       -0.2119,  0.3351, -2.4947, -2.2018, -1.8621,  2.6588,  0.1109,\n",
       "                        1.4239, -0.7761, -1.7568,  1.2066,  1.9608,  2.5422,  2.4843,\n",
       "                       -0.1317, -1.2545,  0.2187,  1.1687, -0.7742, -0.9046,  0.5418,\n",
       "                        2.5444,  0.6208,  2.7872, -1.2381,  1.1733,  0.0199,  2.7919,\n",
       "                       -0.2813,  0.6361,  0.2511, -0.1849, -1.8479, -0.9862,  2.6276,\n",
       "                        1.2928, -1.5641, -1.4841, -1.0617,  2.7587, -0.9432, -2.5480,\n",
       "                        1.8667,  0.1456,  1.4219, -0.0567, -2.9674, -1.3321,  0.1784,\n",
       "                       -1.9538,  1.9685, -1.4734, -1.0056,  2.6409, -0.3519, -2.3682,\n",
       "                       -0.0022, -1.7001, -2.3435, -0.8364, -2.4286,  0.6820,  1.9733,\n",
       "                       -0.3231,  0.5808, -2.1243,  1.8289, -0.9584, -2.2283, -2.5455,\n",
       "                       -2.6821,  0.2015,  1.4053,  2.1768,  0.0893,  0.5953,  2.0563,\n",
       "                        2.4125,  1.7865,  0.4982,  1.8388, -0.1610,  0.1003, -0.1108,\n",
       "                        1.6928, -1.4782,  1.3342,  2.6902, -1.0544, -2.8195, -1.0660,\n",
       "                       -1.8409,  0.0799,  1.4311, -2.2151,  2.4898,  0.9935, -1.8197,\n",
       "                        2.5799,  2.4407, -1.7639, -0.2830, -2.9581,  1.4022, -2.7395,\n",
       "                       -2.6299, -0.0325,  0.9894,  2.3202, -0.3178, -2.6367, -2.8100,\n",
       "                        1.7532, -0.6147, -0.4802, -1.7753,  2.8879,  0.6860, -2.0988,\n",
       "                        1.5281,  1.0806, -1.4616,  0.1668,  0.7562, -1.9986,  1.3493,\n",
       "                        1.1910, -2.6471,  1.8484, -2.7591,  1.2158, -2.8544, -1.4500,\n",
       "                        2.3548, -2.9054, -0.7479,  2.3988, -2.7226,  1.5368, -1.2178,\n",
       "                        1.8638, -0.6702,  2.6690,  1.9835,  0.0925, -1.4135, -1.1935,\n",
       "                       -0.4754, -2.7046, -2.4138, -0.0796, -1.5060, -2.1273, -0.8555,\n",
       "                        2.3688, -0.3583,  2.7709, -0.7322, -1.9674, -1.1361, -1.5454,\n",
       "                        0.5452, -2.4254, -0.1423, -2.0544,  0.1290,  1.4091]])),\n",
       "             ('fc3.bias',\n",
       "              tensor(1.00000e-02 *\n",
       "                     [ 3.7656]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor_local.state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.state_dict(torch.load('checkpoint_critic.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "score = np.zeros(num_agents)\n",
    "agent.reset()\n",
    "\n",
    "while True:\n",
    "    actions = agent.act(states)\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    score += rewards\n",
    "    states = next_states\n",
    "    \n",
    "    if np.any(dones):\n",
    "        break\n",
    "        \n",
    "print(f'Score {(score)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
